#!/usr/bin/env python3
import queue
import sys
import sounddevice as sd
import subprocess
import json
import os
import wave
import numpy as np
import samplerate
import random
import time
from vosk import Model, KaldiRecognizer

# ğŸ”„ Audioindex aus Datei
def get_device_index():
    try:
        with open("/opt/script/audio_index.conf", "r") as f:
            return int(f.read().strip())
    except Exception as e:
        print(f"âŒ Fehler beim Laden des Index: {e}")
        return None

# ğŸ”Š AusgabegerÃ¤t aus Datei
def get_output_device():
    try:
        with open("/opt/script/audio_device.conf", "r") as f:
            return f.read().strip()
    except Exception as e:
        print(f"âŒ Fehler beim Laden des Ausgabe-GerÃ¤ts: {e}")
        return None

# âœ… Konfiguration
SAMPLE_RATE = 48000
VOSK_SAMPLE_RATE = 16000
BUFFER_SIZE = 4000
TRIGGER_WORD = "niko"
RECORD_SECONDS = 16
MODEL_PATH = "/opt/vosk/vosk-de"
RESPONSES_DIR = "/opt/sound/responses"
CONFIRM_DIR = "/opt/sound/confirm"
ERROR_DIR = "/opt/sound/error"
OUTPUT_FILE = "/tmp/command.wav"

# ğŸ“¥ Queue fÃ¼r Resampled Audio
q = queue.Queue()

# ğŸ“¦ Modell laden
print("ğŸ§ Starte Wakeword-Erkennung â€¦ (sage 'niko')")
model = Model(MODEL_PATH)
recognizer = KaldiRecognizer(model, VOSK_SAMPLE_RATE)

# ğŸ¤ GerÃ¤t holen
device = get_device_index()
if device is None:
    print("âŒ Kein Audio-GerÃ¤t gefunden.")
    sys.exit(1)

# ğŸ”Š AusgabegerÃ¤t holen
output_device = get_output_device()

# ğŸ§ Callback mit Resampling
def callback(indata, frames, time, status):
    if status:
        print(status, file=sys.stderr)
    resampled = samplerate.resample(indata, VOSK_SAMPLE_RATE / SAMPLE_RATE, 'sinc_best')
    q.put(resampled.astype('int16').tobytes())

# ğŸš€ Start
with sd.InputStream(samplerate=SAMPLE_RATE, blocksize=BUFFER_SIZE, device=device,
                    dtype='int16', channels=1, callback=callback):
    print("ğŸ™ Lausche auf Wakeword â€¦")

    while True:
        data = q.get()

        if recognizer.AcceptWaveform(data):
            result = json.loads(recognizer.Result())
            print(f"ğŸ“„ Erkannt: {result.get('text', '')}")
            if TRIGGER_WORD in result.get("text", "").lower():
                print(f"âœ… Wakeword erkannt: {TRIGGER_WORD}")

                # ğŸ”Š ZufÃ¤llige Antwort abspielen
                response_files = [f for f in os.listdir(RESPONSES_DIR) if f.endswith(".wav")]
                if response_files:
                    chosen = random.choice(response_files)
                    wav_path = os.path.join(RESPONSES_DIR, chosen)
                    print(f"â–¶ï¸ Spiele: {chosen}")
                    if output_device:
                        subprocess.Popen(["aplay", "-D", output_device, wav_path])
                    else:
                        print("âš ï¸ Kein gÃ¼ltiges Audio-AusgabegerÃ¤t â€“ kann WAV nicht abspielen.")

                # ğŸ™ Aufnahme startet JETZT
                print("ğŸ™ Aufnahme beginnt â€¦")
                recorded_chunks = []
                max_chunks = int(RECORD_SECONDS * VOSK_SAMPLE_RATE / BUFFER_SIZE)

                for _ in range(max_chunks):
                    recorded_chunks.append(q.get())

                # â³ kleiner Puffer am Ende
                time.sleep(0.2)
                try:
                    while True:
                        recorded_chunks.append(q.get_nowait())
                except queue.Empty:
                    pass

                print("ğŸ›‘ Aufnahme beendet.")

                # ğŸ’¾ Speichern
                audio_data = b''.join(recorded_chunks)
                with wave.open(OUTPUT_FILE, 'wb') as wf:
                    wf.setnchannels(1)
                    wf.setsampwidth(2)
                    wf.setframerate(VOSK_SAMPLE_RATE)
                    wf.writeframes(audio_data)

                print(f"ğŸ’¾ Gespeichert unter: {OUTPUT_FILE}")

                # ğŸ§  Transkription aus WAV
                wf = wave.open(OUTPUT_FILE, "rb")
                recognizer = KaldiRecognizer(model, VOSK_SAMPLE_RATE)
                print("ğŸ§  Verarbeite gesprochene Eingabe â€¦")
                while True:
                    chunk = wf.readframes(BUFFER_SIZE)
                    if len(chunk) == 0:
                        break
                    recognizer.AcceptWaveform(chunk)

                result = json.loads(recognizer.FinalResult())
                text = result.get("text", "")
                print(f"ğŸ“ Erkannter Text: {text}")

                # ğŸ”„ Sende an GPTâ†’FHEM
                print("ğŸ¤– Sende an GPT â€¦")
                subprocess.run(["/opt/venv/bin/python", "/opt/script/gpt_to_fhem.py", text])

                # âœ… BestÃ¤tigung oder âŒ Fehler
                if os.path.exists("/tmp/fhem_confirmed"):
                    confirm_files = [f for f in os.listdir(CONFIRM_DIR) if f.endswith(".wav")]
                    if confirm_files:
                        confirm_wav = random.choice(confirm_files)
                        confirm_path = os.path.join(CONFIRM_DIR, confirm_wav)
                        print(f"â–¶ï¸ BestÃ¤tigung: {confirm_wav}")
                        if output_device:
                            subprocess.Popen(["aplay", "-D", output_device, confirm_path])
                    os.remove("/tmp/fhem_confirmed")
                else:
                    error_files = [f for f in os.listdir(ERROR_DIR) if f.endswith(".wav")]
                    if error_files:
                        error_wav = random.choice(error_files)
                        error_path = os.path.join(ERROR_DIR, error_wav)
                        print(f"âŒ Fehlerausgabe: {error_wav}")
                        if output_device:
                            subprocess.Popen(["aplay", "-D", output_device, error_path])
